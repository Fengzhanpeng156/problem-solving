# 内存碎片问题

造成堆内存利用率很低的一个主要原因就是内存碎片化。内存碎片化就是计算机程序在运行过程中，**频繁地内存分配与释放引起的内存空间不连续性问题**，可能导致内存利用率降低甚至无法分配所需的内存。内存碎片主要分为内碎片和外碎片两种类型。



# ThreadCache.cpp

## 1 分配内存

```C
void* ThreadCache::allocate(size_t size)
```

- 处理0分配等非法分配或不足8字节的空间分配

- ```size > MAX_BYTES```大对象直接分配

- 根据分配空间进行内存索引，看属于哪个链表等级

- 在对应索引处更新链表```freeListSize_[index]--;```

- 检查本地自由链表，如果 freeList_[index] 不为空，表示该链表中有可用内存块，```freeList_[index] = *reinterpret_cast<void**>(ptr);```

  - `ptr` 是当前被取出的内存块；

    在这个内存块的前 8 字节（或 4 字节）里，**我们人为存放了“下一个空闲块的地址”**；

    所以可以把 `ptr` 强制转换成 `void**`，然后取值解引用，得到“下一个空闲块地址”：

- 如果线程本地自由链表为空，则从中心缓存获取一批内存

## 2 回收内存

```c
void ThreadCache::deallocate(void* ptr, size_t size)
```

- 大对象直接调用free（）
- 获取size对应的链表索引
- 使用头插法，

```c
    *reinterpret_cast<void**>(ptr) = freeList_[index];
    freeList_[index] = ptr;
```

- 更新对应size1的自由链表大小 ``` freeListSize_[index]++; ```
- 判断是否需要将部分内存回收给中心缓存

## 3 判断是否需要将内存回收给中心缓存

```C
bool ThreadCache::shouldReturnToCentralCache(size_t index)
{
    // 设定阈值，例如：当自由链表的大小超过一定数量时
    size_t threshold = 64; // 例如，64个内存块
    return (freeListSize_[index] > threshold);
}
```

## 4 从中心缓存获取内存

```C
void* ThreadCache::fetchFromCentralCache(size_t index)
```

- 中心缓存获取批量内存

```c
    void* start = CentralCache::getInstance().fetchRange(index);
    if (!start) return nullptr;
```

- 提取第一个内存块作为返回结果，其余放回本地链表

```C
    void* result = start;
    freeList_[index] = *reinterpret_cast<void**>(start);
```

- 遍历这条链表，统计获取了多少个内存块

- 更新freeListSize_，增加获取的内存块数量

##  5 一部分空闲块归还内存给中心缓存

```C
void ThreadCache::returnToCentralCache(void* start, size_t size)
```

- 获取索引与对齐后的大小
- 计算要归还的内存块数量
- 找到第 `keepNum` 个节点（分割点）
- 断开链表

```C
void* nextNode = *reinterpret_cast<void**>(splitNode);
*reinterpret_cast<void**>(splitNode) = nullptr; 
```

```C
        // 更新ThreadCache的空闲链表
        freeList_[index] = start;

        // 更新自由链表大小
        freeListSize_[index] = keepNum;
```

- 将剩余部分返还中心缓存

# PageCache.h

- 单例模式

```C
class PageCache
{
public:
    static const size_t PAGE_SIZE = 4096; // 4K页大小

    static PageCache& getInstance()
    {
        static PageCache instance; // 单例模式，确保全局唯一实例
        return instance;
    }
```

- **`PAGE_SIZE`**：定义内存页大小为4KB（操作系统级内存分配的基本单位）。
- **`getInstance`**：通过静态局部变量实现线程安全的单例模式，确保整个程序中只有一个 `PageCache` 实例，统一管理内存页

- **`allocateSpan`**：分配一段连续的页内存（Span），参数 `numPages` 是请求的页数。
- **`deallocateSpan`**：释放先前分配的Span，需要地址 `ptr` 和页数 `numPages` 作为参数。

- 构造私有化

- **构造函数私有化**：强制通过 `getInstance` 获取单例，避免外部创建多个实例。
- **`systemAlloc`**：底层方法，直接调用操作系统接口（如 `mmap` 或 `VirtualAlloc`）申请大块内存，返回以页为单位的连续地址。

# Center Cache.cpp

- span（内存大小）

```C
// 每次从PageCache获取span大小（以页为单位）
static const size_t SPAN_PAGES = 8;
```

## 1 申请内存```void* CentralCache::fetchRange(size_t index)```

```c
void* CentralCache::fetchRange(size_t index)
```

- 索引大于FREE_LIST_SIZE申请malloc

```C
locks_[index].test_and_set(std::memory_order_acquire
```

- `locks_` 是一个原子布尔数组，比如：`std::atomic_flag locks_[N];`。

  每个 `locks_[i]` 表示一个资源的“锁状态”。

- 原子操作 `test_and_set`：

  - 它的作用是：

    > **检查当前锁状态，如果未锁定，则设置为锁定并返回旧值；如果已锁定，则返回 true。**

  - 即：

    - 如果之前是“没上锁”：返回 `false`，并把它设置为“已上锁”，表示当前线程获得了锁。
    - 如果之前是“已上锁”：返回 `true`，表示锁被别人持有，继续循环等待。

  - `std::memory_order_acquire`：确保**后续操作不会被编译器或 CPU 重排到加锁之前**，用于线程间的内存可见性保证。

## 2 从中心缓存获取内存块

```C
result = centralFreeList_[index].load(std::memory_order_relaxed);
```

- 原子操作
- `relaxed` 表示不要求内存屏障，性能更好

### 2.1 如果中心缓存为空，从页缓存获取新的内存块

#### 2.1.1 如果页缓存也失败，说明内存不足或系统异常，手动释放自旋锁，然后返回 `nullptr`。

```C
 if (!result)
            {
                locks_[index].clear(std::memory_order_release);
                return nullptr;
            }
```

#### 3 将内存块分成小块

```C
char* start = static_cast<char*>(result);
size_t blockNum = (SPAN_PAGES * PageCache::PAGE_SIZE) / size;
```

#### 4 构建链表

```C
for (size_t i = 1; i < blockNum; ++i) 
  {
 void* current = start + (i - 1) * size;
 void* next = start + i * size;
 *reinterpret_cast<void**>(current) = next;
  }
```

**为什么需要 `void**`**：

- 因为 `current` 指向的内存需要存储一个 `void*` 类型的值（即下一个块的地址 `next`），而直接对 `void*` 解引用是非法的（`void*` 是“无类型”指针，编译器不知道如何操作它指向的数据）。
- 通过转换为 `void**`，可以明确告诉编译器：“`ptr` 指向的内存里存储的是一个 `void*` 类型的值，请允许我修改它”

#### 5 更新中心缓存

```C
void* next = *reinterpret_cast<void**>(result);
*reinterpret_cast<void**>(result) = nullptr;
centralFreeList_[index].store(next, std::memory_order_release);
```

`result` 是我们要返回给用户的块，链表的第二个块将作为新的中心缓存头。

`release` 表示这次写操作在其他线程看到之前，不会让之前的写重排到这之后。

### else

```C
            // 保存result的下一个节点
            void* next = *reinterpret_cast<void**>(result);
            // 将result与链表断开
            *reinterpret_cast<void**>(result) = nullptr;
            
            // 更新中心缓存
            centralFreeList_[index].store(next, std::memory_order_release);
```

如果最开始中心缓存不为空，就直接返回当前头节点，同时更新中心缓存为下一个节点。

## 最后

```C
    catch (...) 
    {
        locks_[index].clear(std::memory_order_release);
        throw;
    }

    // 释放锁
    locks_[index].clear(std::memory_order_release);
    return result;
```

`catch (...)` 是一个**通用捕获子句**，表示无论抛出什么类型的异常，这里都能捕获。

`throw;` 表示**继续向上传递异常**，不在此处处理，但确保异常发生时仍然能释放锁，防止死锁。

整段代码用了自旋锁 `locks_[index]` 来保护 `centralFreeList_[index]` 的访问。

`clear()` 是解锁，自旋锁不会自动释放，需要手动 `clear`。

异常或正常都需要释放锁，否则**可能造成多个线程卡死（死锁）**。

所以加上了 `catch (...)`，保证异常时也能释放。

## 3 归还内存```void CentralCache::returnRange(void* start, size_t size, size_t index)```

> **将线程缓存中多余的内存块，归还给中心缓存，以供其他线程重用。**

它通过链表结构维护内存池，自旋锁保障并发安全，释放时兼顾性能与异常安全。

- 如果 `start == nullptr`：没什么好归还的，直接返回。
- 如果 `index` 超过 `FREE_LIST_SIZE`，说明太大，不应该放进中心缓存，可能直接返回给系统。

### 加锁

```C
    while (locks_[index].test_and_set(std::memory_order_acquire)) 
    {
        std::this_thread::yield();
    }
```

使用 `atomic_flag` 的自旋锁，确保对 `centralFreeList_[index]` 的访问是线程安全的。

`yield()` 避免忙等待，给其他线程让出 CPU 时间片。

### 遍历链表，找到末尾节点

```C
    try 
    {
        // 找到要归还的链表的最后一个节点
        void* end = start;
        size_t count = 1;
        while (*reinterpret_cast<void**>(end) != nullptr && count < size) {
            end = *reinterpret_cast<void**>(end);
            count++;
        }
```

### 链接到中心缓存

```C
void* current = centralFreeList_[index].load(std::memory_order_relaxed);
*reinterpret_cast<void**>(end) = current;
centralFreeList_[index].store(start, std::memory_order_release);
```

- 把中心缓存当前的链表 `current` 接在要归还的链表 `end` 后面。

  再把 `start` 设置为 `centralFreeList_` 的新的链表头。

### 异常处理

```C
catch (...) 
{
    locks_[index].clear(std::memory_order_release);
    throw;
}
locks_[index].clear(std::memory_order_release);
```

- 无论是否发生异常，最后都要 `clear()` 解锁，防止死锁。

  使用 `memory_order_release` 表明：其他线程获取这个锁时，一定能看到当前线程在锁内完成的修改。

## 4 从页缓存（`PageCache`）中申请**较大块的内存**

```C
void* CentralCache::fetchFromPageCache(size_t size)
```

- 计算实际所需页数

```C
size_t numPages = (size + PageCache::PAGE_SIZE - 1) / PageCache::PAGE_SIZE;
```

`PageCache::PAGE_SIZE` 一般是 `4096`（即 4KB）。

这里计算的 `numPages` 是为了确保分配的页数能够**覆盖请求的 `size` 大小**，即向上取整。

- 判断内存大小是否适合批量分配（小对象），
- 若请求小于等于 `8 页 × 4096 = 32768 字节 = 32KB`，则为“小对象”，可以一次性取 `8 页`。
- 如果 `size > 32KB`，说明是“大对象”，就按实际需要的页数来分配。

```C
    // 2. 根据大小决定分配策略
    if (size <= SPAN_PAGES * PageCache::PAGE_SIZE) 
    {
        // 小于等于32KB的请求，使用固定8页
        return PageCache::getInstance().allocateSpan(SPAN_PAGES);
    } 
    else 
    {
        // 大于32KB的请求，按实际需求分配
        return PageCache::getInstance().allocateSpan(numPages);
    }
}
```

# PageCache.cpp

## 分配多页内存块```void* PageCache::allocateSpan(size_t numPages)```

- 加锁

```C
std::lock_guard<std::mutex> lock(mutex_);
```

在作用域内自动加解锁，保护后续对 `freeSpans_`、`spanMap_` 的修改。

- 查找合适的空闲Span，在 freeSpans_ 中查找第一个“页数 ≥ numPages”的空闲链表

```C
    auto it = freeSpans_.lower_bound(numPages);
    if (it != freeSpans_.end())
    {
        Span* span = it->second;
```

- 从该链表取出一个 span，如果这个页数类别还有后续节点，就把头指向下一个；否则直接从 map 中移除整条链表。

```C
        if (span->next)
            freeSpans_[it->first] = span->next;
        else
            freeSpans_.erase(it);
```

- 如果span大于需要的numPages则进行分割

```C
if (span->numPages > numPages) 
{
    Span* newSpan = new Span;
    newSpan->pageAddr = static_cast<char*>(span->pageAddr) + 
                        numPages * PAGE_SIZE;
    newSpan->numPages = span->numPages - numPages;
    newSpan->next = nullptr;

    // 将超出部分放回空闲Span*列表头部
    auto& list = freeSpans_[newSpan->numPages];
    newSpan->next = list;
    list = newSpan;

    span->numPages = numPages;
}
```

**把 `newSpan` 放到 `freeSpans_` 中对应页数链表的最前面（更新头指针）**，完成新 span 的链表插入。配合 `newSpan->next = list;`，构建了标准的**单向链表头插入操作**。

分割逻辑：

1. 计算多余部分起始地址 `oldAddr + numPages*PAGE_SIZE`；
2. 把它作为新的 `Span` 回插到 `freeSpans_[剩余页数]`；
3. 原 `span` 的 `numPages` 调整为请求的大小。

- 如果没有合适的span，向系统申请

 **整体流程小结**

1. **加锁** → 安全地访问/修改数据结构。
2. **在 `freeSpans_` 找合适的 span** → 有就取；
   - 取出的 span 若过大 → **分割** → 多余部分回插到 `freeSpans_`。
3. **记录到 `spanMap_`** → 日后释放时可快速查找。
4. **没找到时** → 调用 `systemAlloc` 直接向系统要内存 → 同样封装成 `Span` → 记录到 `spanMap_`。

这样就实现了一个按页数管理大块内存的缓存机制：先复用、再分割、最后才系统分配，极大提升了分配效率与内存利用率。

## 归还内存```void PageCache::deallocateSpan(void* ptr, size_t numPages)```

- 加锁

```C
std::lock_guard<std::mutex> lock(mutex_);
```

- 查找该指针 `ptr` 是否在页缓存的 `spanMap_` 中注册过。

  如果没找到，说明这块内存不是 `PageCache` 分配的，直接返回。

```C
auto it = spanMap_.find(ptr);
if (it == spanMap_.end()) return;
```

- 找到对应Span

```C
Span* span = it->second;
```

- 计算当前 span 后面那块内存（可能的相邻块）的地址 `nextAddr`。

  在 `spanMap_` 中查找是否存在这个地址对应的 span。

```C
void* nextAddr = static_cast<char*>(ptr) + numPages * PAGE_SIZE;
auto nextIt = spanMap_.find(nextAddr);
```

- 尝试合并
  - 检查 `nextSpan` 是否在空闲链表中

```C
Span* nextSpan = nextIt->second;
bool found = false;
auto& nextList = freeSpans_[nextSpan->numPages];
```

​	**-nextSpan 是否链表头**

```C
if (nextList == nextSpan)
{
    nextList = nextSpan->next;
    found = true;
}
```

如果 `nextSpan` 是当前链表的头结点，直接移除它。

​	**是否在链表中间或末尾**

```C
else if (nextList)
{
    Span* prev = nextList;
    while (prev->next)
    {
        if (prev->next == nextSpan)
        {
            prev->next = nextSpan->next;
            found = true;
            break;
        }
        prev = prev->next;
    }
}
```

- 如果 `nextSpan` 被成功移除，就合并它

```C
if (found)
{
    span->numPages += nextSpan->numPages;
    spanMap_.erase(nextAddr);
    delete nextSpan;
}
```

合并当前 span 与 nextSpan 的页数。

从 spanMap 中移除 `nextSpan`。

删除其结构体指针。

- 把 `span` 插入到空闲链表的头部（头插法），便于下次快速分配。

## 向操作系统申请新的内存页块```void* PageCache::systemAlloc(size_t numPages)```

```C
size_t size = numPages * PAGE_SIZE;

// 使用mmap分配内存
void* ptr = mmap(nullptr, size, PROT_READ | PROT_WRITE,
                 MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
if (ptr == MAP_FAILED) return nullptr;

// 清零内存
memset(ptr, 0, size);
return ptr;
```

`nullptr`：表示由系统选择返回的内存地址。

`size`：申请的字节数。

`PROT_READ | PROT_WRITE`：内存区域可读可写。

`MAP_PRIVATE | MAP_ANONYMOUS`：

- `MAP_PRIVATE`：私有映射（写入不影响其他进程）。
- `MAP_ANONYMOUS`：匿名映射（不与任何文件关联）。

`-1` 和 `0`：文件描述符无效（配合 `MAP_ANONYMOUS` 使用）。
